{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d29382dd-2b71-44e5-8581-13ad2301c2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import NuestrasFunciones\n",
    "\n",
    "from names_dataset import NameDataset\n",
    "nd = NameDataset()\n",
    "from countryinfo import CountryInfo\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer \n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import FunctionTransformer, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98c86f1b-263d-46ba-84bd-adde62b6832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic = pd.read_csv(\"In/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "deac01fc-9a85-48c3-93ac-faaf803107a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13d89d0e-7e12-4a1d-a634-cd58458cc42a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age', 'Fare']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def return_float_list(df):\n",
    "    lista_float = []\n",
    "    ser_dtypes = df.dtypes\n",
    "    for i,val in enumerate(ser_dtypes):\n",
    "        if val == \"float\":\n",
    "            lista_float.append(ser_dtypes.index[i])\n",
    "    return lista_float\n",
    "    \n",
    "return_float_list(df_titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fbc14d-3df6-41d3-9b69-3b9a7ed74a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "273e2b63-b93c-4584-892b-024c19fd7cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpia(df):\n",
    "    df.rename(columns = {\"SibSp\": \"SiblingsSpouses\",\"Parch\":\"ParentsChildren\"},inplace = True)\n",
    "    #df.drop(\"PassengerId\",axis = 1,inplace = True)\n",
    "\n",
    "    df.loc[df[\"Sex\"] == \"male\", \"Sex\"] = 1\n",
    "    df.loc[df[\"Sex\"] == \"female\", \"Sex\"] = 0\n",
    "    df[\"Sex\"] =  df[\"Sex\"].astype(\"category\")\n",
    "\n",
    "        \n",
    "    return df       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fad6321d-fd7d-4665-8c89-b7d8379cee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cant_mismo(tick,ser):\n",
    "    lista = []\n",
    "    val_counts = ser.value_counts()\n",
    "    valor = val_counts[tick] -1\n",
    "    return valor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4a3fefb-c8a3-4d23-be4a-892a19fbf7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Operaciones_Ticekt(df):\n",
    "    x = df['Ticket'].apply(lambda x: x.split(\" \"))\n",
    "    \n",
    "    df[\"PostTicket\"] = [i[1] if len(i) == 2 else i[0] for i in x]\n",
    "    df.Ticket = df.Ticket.apply(lambda x: x.replace(\",\",\"\").replace(\".\",\"\").replace(\"/\",\"\").upper())\n",
    "    df[\"Cant_PersonasMismoTicket\"] = df.Ticket.apply(lambda x: cant_mismo(x,df.Ticket))\n",
    "\n",
    "\n",
    "    df[\"PreTicket\"] = [i[0] if len(i) == 2 else \"desconocido\" for i in x]\n",
    "    df.PreTicket = df.PreTicket.apply(lambda x: x.replace(\",\",\"\").replace(\".\",\"\").replace(\"/\",\"\").upper())\n",
    "    df.PreTicket = df.PreTicket.apply(lambda x: x[0] if x[0].lower() != \"s\" else x[0:2])\n",
    "    #df_titanic.PreTicket = df_titanic.PreTicket.apply(lambda x: x if x in [\"SC\",\"SO\"] else x[0])\n",
    "    df.PreTicket = df.PreTicket.apply(lambda x: x if x == \"SO\" else x[0])\n",
    "    df.PreTicket = df.PreTicket.apply(lambda x: \"DESC\" if x == \"D\" else x)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26e0912f-1e75-4de9-a151-0344c3c36598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disgrega_titulo(df):\n",
    "    df = df.copy()\n",
    "    df[\"Titulo_Expandido\"] = df[\"Titulo\"]\n",
    "    for i in df.Titulo_Expandido:\n",
    "        #print(i)\n",
    "        if i in[\"Mr\",\"Mrs\",\"Miss\",\"Master\"]:\n",
    "            \n",
    "            df.loc[((df[\"ParentsChildren\"] == 0) & (df[\"Titulo_Expandido\"] == i)),\"Titulo_Expandido\"] = f\"{i}_SinParentsChildren\"\n",
    "            df.loc[((df[\"ParentsChildren\"] != 0) & (df[\"Titulo_Expandido\"] == i)),\"Titulo_Expandido\"] = f\"{i}_ConParentsChildren\"\n",
    "        \n",
    "        \n",
    "            df.loc[((df[\"Cantidad_MismoApellido\"] == 0) & (df[\"Titulo_Expandido\"] == f\"{i}_SinParentsChildren\")),\"Titulo_Expandido\"] = f\"{i}_SinParentsChildren_SinPersMismoApe\"\n",
    "            df.loc[((df[\"Cantidad_MismoApellido\"] != 0) & (df[\"Titulo_Expandido\"] == f\"{i}_SinParentsChildren\")),\"Titulo_Expandido\"] = f\"{i}_SinParentsChildren_ConPersMismoApe\"\n",
    "            df.loc[((df[\"Cantidad_MismoApellido\"] == 0) & (df[\"Titulo_Expandido\"] == f\"{i}_ConParentsChildren\")),\"Titulo_Expandido\"] = f\"{i}_ConParentsChildren_SinPersMismoApe\"\n",
    "            df.loc[((df[\"Cantidad_MismoApellido\"] != 0) & (df[\"Titulo_Expandido\"] == f\"{i}_ConParentsChildren\")),\"Titulo_Expandido\"] = f\"{i}_ConParentsChildren_ConPersMismoApe\"\n",
    "        \n",
    "        \n",
    "            df.loc[((df[\"SiblingsSpouses\"] != 0) & (df[\"Titulo_Expandido\"] == f\"{i}_SinParentsChildren_SinPersMismoApe\")),\"Titulo_Expandido\"] = f\"{i}_ConSoloHermanastros\"\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a1b7a25-b9b7-42ae-b303-af83e1dc1084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_pais(ape):\n",
    "\n",
    "    try:\n",
    "        dict = nd.search(ape)[\"last_name\"][\"country\"]\n",
    "        maximo = max(zip(dict.values(),dict.keys()))[1]\n",
    "    except TypeError:\n",
    "        try:\n",
    "           dict = nd.search(ape)[\"first_name\"][\"country\"]\n",
    "           maximo = max(zip(dict.values(),dict.keys()))[1]\n",
    "        except TypeError:\n",
    "            maximo = \"Desconodido\"\n",
    "    return maximo\n",
    "\n",
    "def get_language(pais):\n",
    "    try:\n",
    "        idioma = CountryInfo(pais).languages()[0]\n",
    "    except:\n",
    "        return \"Desc\"\n",
    "    return idioma \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc1d29be-e96e-46e6-a5f1-940528ded605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Operaciones_Nombres(df):\n",
    "    \n",
    "    x = df.Name.apply(lambda x: x.split(\",\"))\n",
    "    df[\"Apellido\"] = df.Name.apply(lambda x: x.split(\",\")[0])\n",
    "    df[\"Cantidad_MismoApellido\"] = df[\"Apellido\"].apply(lambda x: cant_mismo(x,df.Apellido))\n",
    "\n",
    "    df[\"Titulo\"] = df.Name.apply(lambda x: x.split(\",\")[1].split(\".\")[0].replace(\" \",\"\"))\n",
    "\n",
    "    df = disgrega_titulo(df)\n",
    "\n",
    "    df[\"Pais\"] = df.Apellido.apply(lambda x: return_pais(x))  \n",
    "    df[\"Idioma\"] = df.Pais.apply(lambda x: get_language(x))\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4556e2e2-06ba-4bc3-ad6a-573193521ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_eng(df):\n",
    "    df = Operaciones_Ticekt(df)\n",
    "    df = Operaciones_Nombres(df)        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3856e7-d451-449b-a04f-07fa569efcc6",
   "metadata": {},
   "source": [
    "#### El test también tiene valores missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580fa0d7-e462-4a58-81fc-86cb30b5a8ac",
   "metadata": {},
   "source": [
    "# Te falta conceptualizar los imputadores y arreglar bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8a5c98e-7a61-424d-a11d-c091b6357102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Imputa_cabin(df):\n",
    "    #Fit\n",
    "    df_ApeCabin = df[[\"Apellido\",\"Cabin\"]].copy().dropna()#.reset_index(drop = True)\n",
    "    df_TicketCabin = df[[\"PostTicket\",\"Cabin\"]].copy().dropna()#.reset_index(drop = True)\n",
    "    \n",
    "    Apellidos_ConCabin = list(df_ApeCabin.Apellido.values)\n",
    "    Tickets_ConCabin = list(df_TicketCabin.PostTicket.values)\n",
    "    #Transform\n",
    "    for idx,(ape, cabina,tick) in enumerate(zip(df.Apellido,df.Cabin,df.PostTicket)):\n",
    "        \n",
    "        if cabina is np.nan:\n",
    "            if ape in Apellidos_ConCabin:\n",
    "                #print(ape)\n",
    "                df.loc[idx, \"Cabin\"] = df_ApeCabin.loc[df[\"Apellido\"] == ape, \"Cabin\"].values[0]\n",
    "            elif tick in Tickets_ConCabin:\n",
    "                df.loc[idx, \"Cabin\"] = df_TicketCabin.loc[df[\"PostTicket\"] == tick, \"Cabin\"].values[0]\n",
    "            else:\n",
    "                df.loc[idx, \"Cabin\"] = \"desconocido\"\n",
    "\n",
    "    df[\"Cabin_Letra\"] = df.Cabin.apply(lambda x: x[0] if x != \"desconocido\" else \"desc\")\n",
    "    return df\n",
    "\n",
    "def imputa_age(df, titulo_expanido = False):\n",
    "\n",
    "    if titulo_expanido:\n",
    "        #Fit\n",
    "        llave = df[[\"Age\",\"Titulo_Expandido\"]]\n",
    "        llave = llave.groupby(\"Titulo_Expandido\").agg(\"mean\").reset_index()\n",
    "        #Transform\n",
    "        for idx, val in enumerate(df.Titulo_Expandido):\n",
    "            if np.isnan(df.Age[idx]):\n",
    "                df.loc[idx, \"Age\"] = llave.loc[llave[\"Titulo_Expandido\"] == val, \"Age\"].values[0]\n",
    "    \n",
    "    else:\n",
    "        df_agg = df[[\"Age\",\"Titulo\"]]\n",
    "        llave = df_agg.groupby(\"Titulo\").agg(\"mean\").reset_index()\n",
    "        for idx, val in enumerate(df.Titulo):\n",
    "            if np.isnan(df.Age[idx]):\n",
    "                df.loc[idx, \"Age\"] = llave.loc[llave[\"Titulo\"] == val, \"Age\"].values[0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4acde0-7453-44c5-b74b-c40371c1575c",
   "metadata": {},
   "source": [
    "### Aplicando lo aprendido en hands on machine learning de Aurelién Gerón, al imputar el test se hará con los datos del train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3126bffa-1160-4df3-aef2-158fbed13480",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputamos cabin asignando misma cabin a personas del mismo apellido, en su defecto ticket, en su defecto desconocido.\n",
    "#Imputamos Age por edad promedio del título o del título disgregado por vínculos familiares a bordo.\n",
    "#Imputamos Cabin por más frecuente por país.\n",
    "class Imputador(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, titulo_expandido = False):\n",
    "        self.titulo_expandido = titulo_expandido  \n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        #CABIN\n",
    "        \n",
    "        self.df_ApeCabin = X[[\"Apellido\",\"Cabin\"]].dropna().copy()#.reset_index(drop = True)\n",
    "        self.df_TicketCabin = X[[\"PostTicket\",\"Cabin\"]].dropna().copy()#.reset_index(drop = True)\n",
    "        self.Apellidos_ConCabin = list(self.df_ApeCabin.Apellido.values)\n",
    "        self.Tickets_ConCabin = list(self.df_TicketCabin.PostTicket.values)\n",
    "        \n",
    "        #AGE\n",
    "        if self.titulo_expandido:\n",
    "            self.llave_titulo = X[[\"Age\",\"Titulo_Expandido\"]]\n",
    "            self.llave_titulo = self.llave_titulo.groupby(\"Titulo_Expandido\").agg(\"mean\").reset_index()\n",
    "        else: \n",
    "            self.llave_titulo = X[[\"Age\",\"Titulo\"]]\n",
    "            self.llave_titulo = self.llave_titulo.groupby(\"Titulo\").agg(\"mean\").reset_index()\n",
    "\n",
    "        #Embarked tiene un par de missings, imputaré por moda por País.\n",
    "        self.df_embarked  = X[[\"Pais\",\"Embarked\"]].dropna().copy().groupby(\"Pais\").apply(lambda x: x.mode().iloc[0]).reset_index(drop=True)\n",
    "\n",
    "        #Fare\n",
    "        self.llave_Fare = X[[\"Fare\",\"Titulo_Expandido\"]]\n",
    "        self.llave_Fare = self.llave_Fare.groupby(\"Titulo_Expandido\").agg(\"mean\").reset_index()\n",
    "\n",
    "\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y=None): \n",
    "        #CABIN\n",
    "        for idx,(ape, cabina,tick) in enumerate(zip(X.Apellido,X.Cabin,X.PostTicket)):\n",
    "            if cabina is np.nan:\n",
    "                if ape in self.Apellidos_ConCabin:\n",
    "                    #X.loc[idx, \"Cabin\"] = 4\n",
    "                    #zz  = self.df_ApeCabin.loc[self.df_ApeCabin[\"Apellido\"] == ape, \"Cabin\"].values[0]\n",
    "                    X.loc[idx, \"Cabin\"] =  self.df_ApeCabin.loc[self.df_ApeCabin[\"Apellido\"] == ape, \"Cabin\"].values[0]\n",
    "                    \n",
    "                    #X.loc[idx, \"Cabin\"] = self.df_ApeCabin.loc[X[\"Apellido\"] == ape, \"Cabin\"].values[0]\n",
    "                    \n",
    "                elif tick in self.Tickets_ConCabin:\n",
    "                    X.loc[idx, \"Cabin\"] = self.df_TicketCabin.loc[self.df_TicketCabin[\"PostTicket\"] == tick, \"Cabin\"].values[0]\n",
    "                    \n",
    "                else:\n",
    "                    X.loc[idx, \"Cabin\"] = \"desconocido\"\n",
    "    \n",
    "        X[\"Cabin_Letra\"] = X.Cabin.apply(lambda x: x[0] if x != \"desconocido\" else \"desc\")\n",
    "\n",
    "        #AGE\n",
    "        for idx, (val, val_exp) in enumerate(zip(X.Titulo, X.Titulo_Expandido)):\n",
    "            #print(\"-------------------------------------------------\")\n",
    "            #print(self.llave_titulo)\n",
    "            #print(\"el error?\")\n",
    "            #print(X.Age)\n",
    "            \n",
    "            if self.titulo_expandido:\n",
    "                if np.isnan(X.Age[idx]):\n",
    "                    X.loc[idx, \"Age\"] = self.llave_titulo.loc[self.llave_titulo[\"Titulo_Expandido\"] == val_exp, \"Age\"].values[0]\n",
    "        \n",
    "            else:\n",
    "                if np.isnan(X.Age[idx]):\n",
    "                    X.loc[idx, \"Age\"] = self.llave_titulo.loc[self.llave_titulo[\"Titulo\"] == val, \"Age\"].values[0]\n",
    "\n",
    "\n",
    "        #Embarked\n",
    "        for idx,(val_embark,val_pais) in enumerate(zip(X.Embarked,X.Pais)):\n",
    "            if val_embark is np.nan:\n",
    "                X.loc[idx, \"Embarked\"] = self.df_embarked.loc[self.df_embarked[\"Pais\"] == val_pais, \"Embarked\"].values[0]\n",
    "\n",
    "\n",
    "        #Fare\n",
    "        for idx, val_titulo in enumerate(X.Titulo_Expandido):\n",
    "            if np.isnan(X.Fare[idx]):\n",
    "\n",
    "                X.loc[idx, \"Fare\"] = self.llave_Fare.loc[self.llave_Fare[\"Titulo_Expandido\"] == val_titulo, \"Fare\"].values[0]\n",
    "\n",
    "               \n",
    "                \n",
    "\n",
    "        return X\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8236499f-e803-4781-8298-fc988551db5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_columna_fit(df,columna):\n",
    "    #fit\n",
    "    # Creo title ranks del df antes de sub-categorizar los títulos por si alguna de las subcategorías no aparece en el test\n",
    "    df_agg = df[[columna,\"Survived\"]].copy()\n",
    "    df_agg = df_agg.groupby([columna], as_index = False).agg(\"mean\").sort_values(by = \"Survived\")\n",
    "\n",
    "    return df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "37a14ffe-7611-4b55-9e41-aa96c76e1020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_columna_transform(df, columna, df_agg):\n",
    "    arr_rank = []\n",
    "    for i in df[columna]:\n",
    "        \n",
    "        if i in list(df_agg[columna]):\n",
    "            arr_rank.append(df_agg.loc[df_agg[columna] == i, \"Survived\"].values[0])\n",
    "\n",
    "        else:\n",
    "            arr_rank.append(0.383838)\n",
    "\n",
    "    #Cambio el valor numérico por rankings del 1 al 19 para que el valor de la variable no sea combinación lineal directa de Y.\n",
    "    # Algoritmo que agarra el df sorted by Titulo_Rank y le asigna una categoría cardinal a cada score.\n",
    "    columna += \"_Rank\"\n",
    "    df[columna] = pd.Series(arr_rank)\n",
    "    df = df.sort_values(by = columna, inplace = False).reset_index(drop = True)\n",
    "    \n",
    "    arr_intermed = list(df[columna])\n",
    "    #Todos los scores iguales a w tendrán el mismo ranking, cuando el score no sea igual a w, se actualiza el ranking a asignar.\n",
    "    w = arr_intermed[0]\n",
    "    j = 1\n",
    "    for i in range(len(df[columna])):\n",
    "        if  arr_intermed[i] == w:\n",
    "            arr_intermed[i] = j\n",
    "        else:\n",
    "            w = arr_intermed[i]\n",
    "            j += 1\n",
    "            arr_intermed[i] = j\n",
    "\n",
    "    df[columna] = pd.Series(arr_intermed)\n",
    "        \n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0b1b8932-377a-4c59-9ccf-0199bdbe1dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asigno rankings a ciertos features del df. Esto lo hago en vez de dejar el survival rate de las personas con ese feature para\n",
    "#así evitar tener features que son directamente combinaciones lineales de la objetuvo.\n",
    "#Tampoco hago one hot enconding por la baja cantidad de observaciones y la pequeña muestra de ciertas categorías.\n",
    "class asigna_ranks(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, usa_titulo_expandido = True):\n",
    "        self.usa_titulo_expandido = usa_titulo_expandido\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.PreTicket_Rank = rank_columna_fit(X,\"PreTicket\")\n",
    "        self.Title_Expandido_Rank = rank_columna_fit(X,\"Titulo_Expandido\")\n",
    "        self.Title_Rank = rank_columna_fit(X,\"Titulo\")\n",
    "        self.Cabin_Letra_Rank = rank_columna_fit(X,\"Cabin_Letra\")\n",
    "        self.Idioma_Rank = rank_columna_fit(X,\"Idioma\")\n",
    "        self.Embarked_Rank = rank_columna_fit(X,\"Embarked\")\n",
    "        \n",
    "\n",
    "        return self \n",
    "        \n",
    "    def transform(self,X,y = None):\n",
    "        X = rank_columna_transform(X,\"PreTicket\",self.PreTicket_Rank)\n",
    "        X = rank_columna_transform(X,\"Titulo\",self.Title_Rank)\n",
    "        X = rank_columna_transform(X,\"Titulo_Expandido\",self.Title_Expandido_Rank)\n",
    "        X = rank_columna_transform(X,\"Cabin_Letra\",self.Cabin_Letra_Rank)\n",
    "        X = rank_columna_transform(X,\"Idioma\",self.Idioma_Rank)\n",
    "        X = rank_columna_transform(X,\"Embarked\",self.Embarked_Rank)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6647ca8e-541c-4b72-bdb5-cd3e29b77a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale, StandardScaler\n",
    "\n",
    "class myScaler(BaseEstimator,TransformerMixin): \n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, copy=None):\n",
    "        columnas_float = return_float_list(X)\n",
    "        escalador = StandardScaler()\n",
    "        X[columnas_float] = escalador.fit_transform(X[columnas_float])\n",
    "        \n",
    "        for idx,feature in enumerate(columnas_float):\n",
    "            X[feature] += abs(min(X[feature]))+0.0001\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4033404b-9496-4818-a72c-98fe3a779698",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic = pd.read_csv(\"In/train.csv\")\n",
    "pipep = Pipeline([\n",
    "            ('Limpiar', FunctionTransformer(limpia)),\n",
    "            ('feat_eng', FunctionTransformer(feat_eng)),\n",
    "            ('imputa', Imputador()),\n",
    "            ('Rank_assign', asigna_ranks()),\n",
    "            ('escala', myScaler())   \n",
    "        ])\n",
    "\n",
    "\n",
    "df_train = pipep.fit_transform(df_titanic.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "10b7fedb-e081-4c6b-b829-9915fc6b6a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"Out/df_imputed_transformed_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1aa955-0047-417d-b662-3751c02a167c",
   "metadata": {},
   "source": [
    "## Test se transforma más no se ajusta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2d498a65-5de1-4b38-968a-2c02b6638f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"In/test.csv\")\n",
    "df_test = pipep.transform(df_test.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1137df96-3687-43e1-803f-aeaa8a1b831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(\"Out/df_imputed_transformed_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b7de00ba-7ec2-46f4-94d1-331191af1678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId                 0\n",
       "Pclass                      0\n",
       "Name                        0\n",
       "Sex                         0\n",
       "Age                         0\n",
       "SiblingsSpouses             0\n",
       "ParentsChildren             0\n",
       "Ticket                      0\n",
       "Fare                        0\n",
       "Cabin                       0\n",
       "Embarked                    0\n",
       "PostTicket                  0\n",
       "Cant_PersonasMismoTicket    0\n",
       "PreTicket                   0\n",
       "Apellido                    0\n",
       "Cantidad_MismoApellido      0\n",
       "Titulo                      0\n",
       "Titulo_Expandido            0\n",
       "Pais                        0\n",
       "Idioma                      0\n",
       "Cabin_Letra                 0\n",
       "PreTicket_Rank              0\n",
       "Titulo_Rank                 0\n",
       "Titulo_Expandido_Rank       0\n",
       "Cabin_Letra_Rank            0\n",
       "Idioma_Rank                 0\n",
       "Embarked_Rank               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16eac37-7843-4cf6-86ff-13332fefde41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
